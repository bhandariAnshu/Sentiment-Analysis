# Sentiment-Analysis of Nepali tweets on moving abroad
In recent years, a substantial increase has been observed in the number of Nepali citizens migrating to other countries, which may be attributed to the pursuit of better opportunities and stability in response to political and economic challenges in Nepal. By analyzing the sentiments expressed on social media platforms like Twitter, insights can be gained into the various factors shaping public attitudes toward moving abroad. The tweets collected in the Nepali language are required to be translated into English for further processing. Preprocessing steps, including data cleaning, stop-word removal, normalization, and tokenization, are applied. Following this, classifier algorithms such as Support Vector Machine (SVM), Naïve Bayes, Logistic Regression, and Random Forest are utilized to train the model by dividing the collected data into training and testing datasets. The model's performance is then evaluated using various evaluation metrics, including F1-score, accuracy, and precision.
Data collection
Data collection was done manually by searching keywords in twitter such as "बिदेश जानु" (meaning "going abroad"), "माइग्रेशन" (migration) etc. The collected tweets were then translated into English, also manually by using different tools and techniques. Further, thus translated tweets were classified in accordance to their polarity as negative (0) or positive (1). The data then was stored in a structured format, typically as a CSV file, which includes the tweet’s text, translated tweets, polarity for further analysis. In total, we collected 976 tweets, of which 462 were classified as negative, while 512 were classified as positive. This dataset was then used to analyze the overall sentiment and public opinion regarding migration and opportunities within and outside Nepal. This dataset gave us a clearer picture of how people feel about migration, showing that slightly more individuals lean towards leaving Nepal.
**Data preprocessing**
After the collection of data, we processed with the data preprocessing stage. Preprocessing is an essential stage for cleaning and standardizing the data. We apply the following pre-processing steps to the dataset: 
1)	Stop-words filtering: removing all stop-words, which are words that do not contribute to the overall meaning and sentiment of the tweet (example: ‘an’, ‘this’, ‘who’, ‘the’, etc.).
2)	Words tokenization: each tweet was broken into smaller parts, called tokens.
3)	Numeric Removal: preprocessing step where all numeric values (such as digits or numbers) are removed from the text data.
4)	Stemming: we reduce words to their root or base form which helps in standardizing
**Implementation**
The sentiment analysis process begins with data collection. Twitter data was manually collected by searching keywords in twitter. The collected tweets were then translated into English. Further, translated tweets were classified in accordance to their polarity. The data then was stored in a structured format, typically as a CSV file. The next step is preprocessing, which involves cleaning the text data by removing stop-words, applying lemmatization or stemming, and eliminating special characters and numbers. Tokenization was then performed to break down the text into individual words, called tokens. The cleaned data is converted into numerical features using the TF-IDF Vectorizer, which measures the importance of words within the dataset. The dataset is split into training, testing and validation sets to evaluate the classifier's performance using various metrics. These features are then used to train a Support Vector Machine (SVM) classifier, Naïve Bayes Random, forest and logistic regression to categorize tweets into positive or negative sentiments.
**Result**
SVM model was trained using the training data. During training, we employed grid search to optimize the regularization parameter C, testing values between 0.1 and 5. The optimal parameter was selected for training the final SVM model. However, the observed accuracy was still not satisfactory.To improve model performance, we expanded the dataset by incorporating additional data. The data collection process was carefully designed to ensure a balanced distribution of sentiments, maintaining an equal proportion of positive and negative sentiment tweets. This approach aimed to minimize bias and enhance the reliability and accuracy of sentiment classification.

Additionally, we experimented with three other models: Logistic Regression, Naïve Bayes, and Random Forest. Each model was trained, and their respective accuracies were evaluated. Among them, Random Forest demonstrated superior performance in capturing sentiment patterns.
After training the models on the training set and evaluating them on the testing set, we obtained 77.85% accuracy using SVM, 84.56% using Logistic Regression, 79.87% using Naïve Bayes and 85.23% using Random Forest algorithms.
The performance of four machine learning algorithms: Support Vector Machine (SVM), Logistic Regression, Naïve Bayes, and Random Forest was compared based on their accuracy in sentiment classification. Among the models trained, Random Forest achieved the highest accuracy of 85.23%, demonstrating its strong capability in capturing patterns within the dataset. Logistic Regression also performed well, with an accuracy of 84.56%, suggesting that it effectively handles the textual data’s linear relationships. Naïve Bayes, which operates under the assumption that features are independent, achieved an accuracy of 79.87%. While it outperformed SVM, its accuracy was slightly lower than that of Logistic Regression and Random Forest. he Support Vector Machine (SVM) had the lowest accuracy at 77.85%, indicating that it might struggle with complex decision boundaries in this dataset.



